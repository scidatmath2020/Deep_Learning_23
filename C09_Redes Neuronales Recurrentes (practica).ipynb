{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 1: Análisis de sentimiento en texto\n",
    "\n",
    "Las RNN funciona de forma particularmente bien a la hora de tratar con texto, ya que por definición el texto es una secuencia ordenada de palabras, y las RNN están especializadas en información secuencial.\n",
    "\n",
    "En este ejemplo vamos a hacer un modelo que haga **Análisis de Sentimiento**. Estos análisis consisten en dado un texto, predecir si el texto es un texto con tono positivo o negativo.\n",
    "\n",
    "Para ello vamos a usar un dataset de entrenamiento creado por la Sociedad Española del Procesado de Lenguaje Natural (SEPLN), y que usan en una conferencia llamada TASS (Taller de Análisis Semántico en la SEPLN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = pd.read_csv(\"texto_extendido.csv\",encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = tweets_corpus.rename(columns={\"polarity\":\"value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = tweets_corpus.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus.value.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polaridades = pd.get_dummies(tweets_corpus.value)\n",
    "polaridades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polaridades_one_hot = polaridades.values\n",
    "polaridades_one_hot[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polaridades_dict = dict(zip(range(6), polaridades.columns))\n",
    "polaridades_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamos el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a tokenizar los tweets. Vamos a convertirlos en vectores de números, donde cada número representa una palabra. Usaremos las 1500 palabrás más comunes en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_palabras = 1500\n",
    "tokenizer = Tokenizer(num_words=max_palabras)\n",
    "tokenizer.fit_on_texts(tweets_corpus.content.values)\n",
    "X = tokenizer.texts_to_sequences(tweets_corpus.content.values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el tweet más largo tiene 32 palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear un mapa inverso de la lista de palabras, esto nos permite reconstruir un tweet en función de su versión vectorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_inverso = dict(map(reversed, tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_inverso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así si tomamos el primer tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus.content.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos su versión vectorizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reconstruirlo con el mapa_inverso del tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[mapa_inverso[i] for i in X[0] if i in mapa_inverso]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos la RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como capa de entrada vamos a usar la capa [`Embedding`](https://keras.io/layers/embeddings/). Es una capa que se encarga de transformar una matriz de texto (donde cada número representa una palabra), en una matriz que representa las relaciones entre las frases  en función de sus palabras.\n",
    "\n",
    "Digamos que un Embedding (word embedding) es una forma mejor de representar texto (captura mejor la información)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "\n",
    "numero_clases = 6\n",
    "\n",
    "modelo_sentimiento = Sequential()\n",
    "modelo_sentimiento.add(Embedding(max_palabras, 128, input_length=X.shape[1]))\n",
    "modelo_sentimiento.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "modelo_sentimiento.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "#modelo_sentimiento.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "modelo_sentimiento.add(Dense(numero_clases, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_sentimiento.compile(loss = 'categorical_crossentropy', optimizer='adam',\n",
    "                           metrics = ['accuracy'])\n",
    "print(modelo_sentimiento.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = polaridades_one_hot\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "batch_size = 256\n",
    "early_stop = EarlyStopping(monitor='accuracy', min_delta=0.00001, patience=5, verbose=1)\n",
    "modelo_sentimiento.fit(X_train, Y_train, epochs=50, batch_size=batch_size, verbose=1,\n",
    "                      callbacks=[early_stop]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora evaluamos con los datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, precision_test = modelo_sentimiento.evaluate(X_test, Y_test)\n",
    "precision_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos tomar una nueva frase y predecir su polaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_frase = \"Qué bonito es el amor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_frase_tokenizada = tokenizer.texts_to_sequences([nueva_frase])\n",
    "nueva_frase_tokenizada_pad = pad_sequences(nueva_frase_tokenizada, maxlen=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_frase_tokenizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_frase_tokenizada_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = modelo_sentimiento.predict(nueva_frase_tokenizada_pad)\n",
    "predicted_class = np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polaridades_dict[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Temporales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar un dataset que contiene el número de pasajeros de avión internacionales por mes, obtenido de [este link](https://www.kaggle.com/andreazzini/international-airline-passengers).\n",
    "\n",
    "En concreto vamos a intentar predecir el número de pasajeros de líneas aereas los últimos meses del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pasajeros = pd.read_csv(\"international-airline-passengers.csv\",sep=\";\")\n",
    "pasajeros.columns = [\"mes\", \"pasajeros\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasajeros.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable objetivo de este modelo será predecir el volumen de pasajeros del mes siguiente. Podemos usar la función de pandas `shift` para mover la columna del número de pasajeros una posición hacia arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasajeros[\"pasajeros_1\"] = pasajeros[\"pasajeros\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasajeros.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al hacer esto la última fila no tiene un valor para predecir, la eliminamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasajeros = pasajeros.drop(143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasajeros_x = pasajeros[\"pasajeros\"].astype(float).values\n",
    "pasajeros_y = pasajeros[\"pasajeros_1\"].astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_periodos = len(pasajeros)\n",
    "pct_test = 0.2\n",
    "\n",
    "n_train = int(n_periodos * (1-pct_test))\n",
    "n_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre, estandarizamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pasajeros_x.reshape(-1, 1))\n",
    "\n",
    "pasajeros_x_std = scaler.transform(pasajeros_x.reshape(-1, 1))\n",
    "pasajeros_y_std = scaler.transform(pasajeros_y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pasajeros_x_std[:n_train]\n",
    "x_test = pasajeros_x_std[n_train:]\n",
    "\n",
    "y_train = pasajeros_y_std[:n_train]\n",
    "y_test = pasajeros_y_std[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,1,1)\n",
    "x_test = x_test.reshape(-1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lstm = Sequential()\n",
    "modelo_lstm.add(GRU(32, return_sequences = True,input_shape=(1, 1)))\n",
    "modelo_lstm.add(GRU(32,return_sequences = True))\n",
    "modelo_lstm.add(GRU(32))\n",
    "modelo_lstm.add(Dense(1))\n",
    "modelo_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lstm.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "modelo_lstm.fit(x_train, y_train, epochs=100, batch_size=1, verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "train_pred = scaler.inverse_transform(modelo_lstm.predict(x_train))\n",
    "y_train_original = scaler.inverse_transform(y_train)\n",
    "error_train = np.sqrt(mean_squared_error(y_train_original, train_pred))\n",
    "\n",
    "error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_pred = scaler.inverse_transform(modelo_lstm.predict(x_test))\n",
    "y_test_original = scaler.inverse_transform(y_test)\n",
    "error_test = np.sqrt(mean_squared_error(y_test_original, test_pred))\n",
    "\n",
    "error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_plot = np.zeros(pasajeros_y.shape)\n",
    "test_pred_plot[-test_pred.shape[0]:] = test_pred[:,0]\n",
    "\n",
    "test_pred_plot[:-test_pred.shape[0]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pasajeros_y)\n",
    "plt.plot(train_pred, label=\"predicción train\")\n",
    "plt.plot(test_pred_plot, label=\"predicción test\")\n",
    "plt.title(\"Número de pasajeros internacionales\")\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
