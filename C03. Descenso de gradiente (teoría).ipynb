{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso de gradiente\n",
    "\n",
    "Se trata de un método de optimización local. Es decir, un método para encontrar un máximo o un mínimo locales de una función.\n",
    "\n",
    "Generalmente se le utiliza para minimizar una función de pérdidas, que en nuestro caso es el error del modelo. Por lo tanto, es una de las piezas fundamentales de cómo las redes neuronales aprenden a encontrar pesos óptimos.\n",
    "\n",
    "Supongamos que tenemos la siguiente función: $f$ dada por $f(x)=x^2-2x+4$, y queremos encontrar su mínimo.\n",
    "![imagenes](im10.png)\n",
    "\n",
    "De nuestras clases de cálculo, sabemos que una forma es hacer $f^\\prime(x)=0$, de donde tenemos $2x-2=0$ y por lo tanto en $x=1$ se encuentra el mínimo de la función. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema se puede plantear de manera mucho más compleja: supongamos que $F:\\mathbb{R}^n\\to\\mathbb{R}^m$ viene dada por $$F(x_1,x_2,...,x_n)=(f_1(x_1,...,x_n),f_2(x_1,...,x_n),...,f_m(x_1,...,x_n)).$$ Es decir, $F$ es una función de variable vectorial y valor vectorial.\n",
    "\n",
    "Entonces, encontrar el mínimo de $F$ equivale a resolver el sistema\n",
    "$$\\left(\\begin{matrix}\\frac{\\partial f_1}{\\partial x_1}&\\frac{\\partial f_1}{\\partial x_2}&...&\\frac{\\partial f_1}{\\partial x_n}\\\\\\frac{\\partial f_2}{\\partial x_1}&\\frac{\\partial f_2}{\\partial x_2}&...&\\frac{\\partial f_2}{\\partial x_n}\\\\\\vdots&\\vdots&\\vdots&\\vdots\\\\\\frac{\\partial f_m}{\\partial x_1}&\\frac{\\partial f_m}{\\partial x_2}&...&\\frac{\\partial f_m}{\\partial x_n}\\end{matrix}\\right)\\left(\\begin{matrix}a_1\\\\a_2\\\\\\vdots\\\\a_n\\end{matrix}\\right)=\\left(\\begin{matrix}0\\\\0\\\\\\vdots\\\\0\\end{matrix}\\right)$$\n",
    "\n",
    "Debido a múltiples razones, computacionalmente no siempre es posible resolver el sistema anterior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como alternativa a este problema, se tiene el **Método del gradiente**. Este consiste en resolver de manera iterativa, para funciones de una variable real a los reales, de la siguiente manera: $$x_{i+1}=x_i-\\alpha f^\\prime(x_i)$$ donde $\\alpha$ la *magnitud de paso* que indica cuánto ha de modificarse $x_i$ en cada iteración.\n",
    "\n",
    "Por ejemplo, supongamos que se elige $x_1=3$ (este se elige al azar) y $\\alpha=0.02$. Como $f^\\prime(x)=2x-2$ entonces $x_2=3-0.02(2\\cdot3-2)=2.92$. De la misma manera se obtiene $x_3=2.84$, $x_4=2.76$, etc.\n",
    "\n",
    "Si para cada $i$ graficamos el punto $(i,x_i)$, obtenemos la siguiente gráfica:\n",
    "![imagenes](im11.png)\n",
    "\n",
    "Observamos que $\\lim_{i\\to\\infty}x_i=1$, que es donde sabíamos que se alcanzaba el mínimo de la función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso mas complicado de $F(x_1,x_2,...,x_n)=(f_1(x_1,...,x_n),f_2(x_1,...,x_n),...,f_m(x_1,...,x_n))$, la iteración se escribe como $$\\boldsymbol{x_{i+1}}=\\boldsymbol{x_i}-\\alpha\\nabla(F(\\boldsymbol{x_i}))$$\n",
    "\n",
    "Esto es lo que se conoce como **descenso de gradiente en grupo** (batch descent gradient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente descendiente estocástico\n",
    "\n",
    "Una manera de evitar computar el error total de todas las observaciones es el método de Gradiente descendiente estocástico (SGD). \n",
    "\n",
    "En este método, en lugar de calcular el coste de todas las operaciones en un paso único, tomamos **minipasos** donde aplicamos el método de gradiente usual al error de cada observación individual. Para que esto funcione y que converja al punto de error mínimo es necesario que dichas observaciones estén ordenadas de manera aleatoria.\n",
    "\n",
    "Básicamente, se introduce una única muestra aleatoria en cada iteración. El gradiente se calculará para esa muestra concreta, lo que supone la introducción de la deseada aleatoriedad, dificultando así el estancamiento. El problema de esta versión es su lentitud, ya que necesita de muchas más iteraciones, y además no aprovecha los recursos disponibles.\n",
    "\n",
    "**Ventajas del SGD**\n",
    "\n",
    "* Si la función objetivo es la suma de de costos individuales (errores) sobre un conjunto muy grande de datos, la muestra suele ser representativa y producir un valor muy cercano al de la población.\n",
    "\n",
    "* Se reduce el número de cálculos en cada iteración.\n",
    "\n",
    "* Cuando hay datos atípicos (outliers), las muestras pueden ser robustas a esas “pocas” grandes desviaciones (salvo en aquellas muestras que sean incluidos, que se esperan sean pocas).\n",
    "\n",
    "* Si la función objetivo es ruidosa (tiene muchos mínimos locales pequeños). El gradiente estocástico permite suavizar la función objetivo y reduce el riesgo de tener una convergencia temprana.\n",
    "\n",
    "**Desventajas del SGD:**\n",
    "\n",
    "* El efecto de los outliers en el gradiente de una muestra puede afectar mas fuertemente y desviar al algoritmo de su trayectoria de convergencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La intimidad de SGD\n",
    "\n",
    "Recordemos nuestro problema **general**: queremos encontrar los parámetros $\\boldsymbol{w}=(w_1,...,w_n)$ de tal manera que se minimize nuestra función de coste. En abstracto: hallar $\\boldsymbol{w}$ tal que el número $$C(\\boldsymbol{w})=\\frac{1}{M}\\sum_{i=1}^ML(g(\\boldsymbol{x_i},\\boldsymbol{w}),d_i)$$ sea mínimo. Notemos que en el caso estudiado en el capítulo anterior, tenemos:\n",
    "\n",
    "* $g(\\boldsymbol{x_i},\\boldsymbol{w})=w_0x_{i0}+w_1x_{i1}+...+w_nx_{in}$.\n",
    "* $L(g(\\boldsymbol{x_i},\\boldsymbol{w}),d_i)=|d_i-f(w_0x_{i0}+w_1x_{i1}+...+w_nx_{in})|=|d_i-y_i|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de descenso de gradiente usual utiliza la pérdida promedio de **todos** los datos de entrenamiento **al mismo tiempo** para minimizar la función de costo. Por lo tanto la fórmula de actualización es $$\\boldsymbol{w}(t+1)=\\boldsymbol{w}(t)-\\alpha\\nabla L(\\boldsymbol{w}(t)).$$\n",
    "\n",
    "Por lo tanto el método clásico necesita **atravesar todos los datos** cada vez que hace una actualización de $\\boldsymbol{w}$. En cambio, el SGD utiliza la pérdida de una sola observación para aproximar la pérdida promedio: $$C(\\boldsymbol{w};\\boldsymbol{x_i},y_i)=G(f(\\boldsymbol{x_i},\\boldsymbol{w}),y_i),$$ de donde $$\\nabla C(\\boldsymbol{w};\\boldsymbol{x_i},y_i)=\\nabla G(f(\\boldsymbol{x_i},\\boldsymbol{w}),y_i)$$ \n",
    "\n",
    "Finalmente, esta única observación con la que, en cada paso, mejora las estimaciones de $\\boldsymbol{w}$ se elige de manera aleatoria reordenando cada vez toda la tabla y recalcula como $$w_i(t+1)=w_i(t)+(d_j-y_j(t))x_{ji}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
