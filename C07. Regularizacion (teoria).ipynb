{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularización\n",
    "\n",
    "Recordemos qué son los problemas de sobregeneralización y sobreajuste:\n",
    "\n",
    "<img src=\"im28.png\">\n",
    "\n",
    "**¿Cómo resolvemos estos problemas en Deep Learning?**\n",
    "\n",
    "## Métodos del machine learning\n",
    "\n",
    "Los tipos más comunes de regularización, basados en el machine learning, son:\n",
    "\n",
    "**L1:**  $J(\\theta,x,y)+\\lambda\\displaystyle\\sum|\\theta|$\n",
    "\n",
    "**L2:**  $J(\\theta,x,y)+\\lambda\\displaystyle\\sum\\theta^2$\n",
    "\n",
    "**ElasticNet:**  $J(\\theta,x,y)+\\lambda_1\\displaystyle\\sum|\\theta|+\\lambda_2\\displaystyle\\sum\\theta^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos propios del deep learning\n",
    "\n",
    "### Dropout\n",
    "\n",
    "Consiste en ignorar un porcentaje $p$ de unidades de una capa densa.\n",
    "\n",
    "Esto obliga a la red a ser más robusta respecto al input que espera (ya que las activaciones cambian en cada iteración al tener neuronas apagadas). Sin embargo, esto implica que tardará más en converger a la solución óptima.\n",
    "\n",
    "<img src=\"im29.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización Batch\n",
    "\n",
    "<img src=\"im30.png\">\n",
    "\n",
    "Si cambiamos la distribución de los datos de prueba (por ejemplo, si son tomados de otra población diferente a la de la cual se tomó la muestra de los datos de entrenamiento), nuestro modelo no será capaz de clasificar correctamente (a esto se le llama covariate shift). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si lo piensas bien, de hecho esto pasa constantemente en la red neuronal, porque en la propagación hacia adelante y hacia atrás, a partir de la capa 1, los inputs van cambiando.**\n",
    "\n",
    "<img src=\"im31.png\">\n",
    "\n",
    "La normalización batch simplemente se encarga de estandarizar (media 0, varianza 1) los pesos de cada etapa en cada grupo (batch) de observaciones del entrenamiento.\n",
    "\n",
    "Así, los pesos de todas las capas, tanto las iniciales como las finales, son similares y se evita que las capas finales se enfoquen en captar el ruido de las capas iniciales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
